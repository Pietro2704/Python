{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Desafio\n",
        "Você foi contratado por um banco para conseguir definir o score de crédito dos clientes. Você precisa analisar todos os clientes do banco e, com base nessa análise, criar um modelo que consiga ler as informações do cliente e dizer automaticamente o score de crédito dele:\n",
        "\n",
        "- Ruim\n",
        "- Ok\n",
        "- Bom"
      ],
      "metadata": {
        "id": "QhDnD1BvUH6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar e analisar tabela\n",
        "import pandas as pd\n",
        "df = pd.read_csv('clientes.csv')\n",
        "df.info()\n",
        "\n",
        "# Colunas Importantes\n",
        "display(\n",
        "    df[\n",
        "        ['profissao','mix_credito','comportamento_pagamento']\n",
        "      ].tail(25)\n",
        "    )"
      ],
      "metadata": {
        "id": "CNe-N9VFTwUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LabelEncoder\n",
        "Vamos explorar a classe `LabelEncoder` da biblioteca `scikit-learn` (sklearn.preprocessing).\n",
        "\n",
        "Essa ferramenta é amplamente utilizada no pré-processamento de dados para transformar rótulos categóricos em valores numéricos, o que é essencial para muitos algoritmos de machine learning que exigem entradas numéricas.\n",
        "\n",
        "Ela converte variáveis categóricas (não numéricas) em números inteiros. Cada categoria única recebe um valor inteiro distinto. Essa codificação é simples e direta, tornando-a útil para transformar dados antes de alimentá-los em modelos de aprendizado de máquina.\n",
        "\n",
        "## Quando Usar LabelEncoder\n",
        "- __Rótulos de Classes:__ É ideal para transformar rótulos de classe (variável alvo) em números. Por exemplo, transformar categorias como \"gato\", \"cachorro\" e \"pássaro\" em 0, 1 e 2, respectivamente.\n",
        "\n",
        "- __Variáveis Categóricas Ordinais:__ Quando as categorias têm uma ordem intrínseca, como \"baixo\", \"médio\" e \"alto\".\n",
        "\n",
        "## Quando Não Usar LabelEncoder\n",
        "- __Variáveis Categóricas Nominais:__ Para variáveis categóricas sem ordem intrínseca (como cores: \"vermelho\", \"verde\", \"azul\"), é preferível usar `OneHotEncoder` para evitar que o modelo interprete uma ordem inexistente entre as categorias.\n",
        "\n",
        "- __Dados de Entrada:__ LabelEncoder não deve ser usado para transformar variáveis independentes (features) diretamente, especialmente se não houver uma ordem lógica entre as categorias.\n",
        "\n",
        "## Quando Usar OneHotEncoder em vez de LabelEncoder?\n",
        "- Se as categorias __não possuem ordem__ e são puramente nominais, como \"cor\" ou \"tipo de animal\", use o __`OneHotEncoder`__. Isso garante que o modelo não atribua significado a uma ordem numérica.\n",
        "\n",
        "- Se as categorias __possuem ordem__, como \"baixo\", \"médio\" e \"alto\", você pode usar o __`LabelEncoder`__, mas tome cuidado com a interpretação do modelo."
      ],
      "metadata": {
        "id": "JMo7-Wt6VmCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificando colunas texto para número\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "codificador = LabelEncoder()\n",
        "\n",
        "# Codificar e transformar as colunas categóricas em números.\n",
        "df['profissao'] = codificador.fit_transform(df['profissao'])\n",
        "df['mix_credito'] = codificador.fit_transform(df['mix_credito'])\n",
        "df['comportamento_pagamento'] = codificador.fit_transform(df['comportamento_pagamento'])\n",
        "\n",
        "display(\n",
        "    df[\n",
        "        ['profissao','mix_credito','comportamento_pagamento']\n",
        "      ].tail(25)\n",
        "    )"
      ],
      "metadata": {
        "id": "EUkDcT9RVFx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparando Dados para Aprendizado de Máquina\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = df.drop(columns=['score_credito', 'id_cliente'])\n",
        "y = df['score_credito']\n",
        "\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y)"
      ],
      "metadata": {
        "id": "T0eDppzNap1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Explicação:__\n",
        "\n",
        "- __Separação de variáveis:__ x contém as colunas que serão usadas como características (features), enquanto y contém a variável que queremos prever (target).\n",
        "\n",
        "- __Divisão do conjunto de dados:__ A função train_test_split() divide os dados em conjuntos de treinamento e teste. Isso permite que o modelo seja treinado em uma parte dos dados e testado em outra, garantindo uma avaliação justa do desempenho."
      ],
      "metadata": {
        "id": "Y0ETSITCekFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algoritmos de aprendizado de máquina\n",
        "Eles são usados para construir modelos preditivos com base em dados, e cada um tem suas características e aplicações específicas.\n",
        "## Random Forest\n",
        "__Random Forest__ é uma técnica que utiliza um conjunto de árvores de decisão para realizar a classificação ou regressão.\n",
        "\n",
        "- __Baseado em Árvores de Decisão:__ O Random Forest constrói múltiplas árvores de decisão durante o treinamento. Cada árvore é construída com um subconjunto aleatório dos dados e das características.\n",
        "\n",
        "- __Bagging:__ Utiliza a técnica de bootstrap aggregating (bagging), onde várias árvores são treinadas em diferentes amostras do conjunto de dados e, em seguida, suas previsões são combinadas para obter um resultado mais robusto e generalizado.\n",
        "\n",
        "## K-Nearest Neighbors (KNN)\n",
        "- __Não Baseado em Árvores de Decisão:__ KNN é um algoritmo baseado em distância, onde a previsão para um ponto é feita com base nos K vizinhos mais próximos no espaço de características.\n",
        "\n",
        "- __Simples e Intuitivo:__ Ao contrário das árvores de decisão, KNN não constrói um modelo explícito; em vez disso, armazena o conjunto de treinamento e realiza cálculos de distância para fazer previsões."
      ],
      "metadata": {
        "id": "YY1N7znQhA89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinando os Modelos de IA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "modelo_arvore_decisao = RandomForestClassifier()\n",
        "modelo_knn = KNeighborsClassifier()\n",
        "\n",
        "modelo_arvore_decisao.fit(x_treino, y_treino)\n",
        "modelo_knn.fit(x_treino, y_treino)"
      ],
      "metadata": {
        "id": "Lf7zYI0FfNWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtendo Previsões\n",
        "previsao_arvore = modelo_arvore_decisao.predict(x_teste)\n",
        "previsao_knn = modelo_knn.predict(x_teste)\n",
        "\n",
        "# Verificando a Precisão de Cada Modelo\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(y_teste, previsao_arvore))\n",
        "print(accuracy_score(y_teste, previsao_knn))"
      ],
      "metadata": {
        "id": "J2RFD5ThfmM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisar oq tem nesse arquivo\n",
        "tabela_novos_clientes = pd.read_csv('novos_clientes.csv')\n",
        "tabela_novos_clientes"
      ],
      "metadata": {
        "id": "AsXOg0FfkROr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazendo Novas Previsões\n",
        "tabela_novos_clientes = pd.read_csv('novos_clientes.csv')\n",
        "\n",
        "tabela_novos_clientes['profissao'] = codificador.fit_transform(tabela_novos_clientes['profissao'])\n",
        "tabela_novos_clientes['mix_credito'] = codificador.fit_transform(tabela_novos_clientes['mix_credito'])\n",
        "tabela_novos_clientes['comportamento_pagamento'] = codificador.fit_transform(tabela_novos_clientes['comportamento_pagamento'])\n",
        "\n",
        "previsoes = modelo_arvore_decisao.predict(tabela_novos_clientes)\n",
        "print(previsoes)\n"
      ],
      "metadata": {
        "id": "Xwc0yCG8gKnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Explicação:__\n",
        "- __Importação de Novos Dados:__ Lemos um novo arquivo CSV que contém dados de novos clientes.\n",
        "\n",
        "- __Codificação das Novas Entradas:__ As colunas categóricas do novo DataFrame são codificadas da mesma forma que fizemos anteriormente.\n",
        "\n",
        "- __Fazendo Previsões:__ Usamos o modelo treinado (modelo_arvore_decisao) para prever o score de crédito dos novos clientes, imprimindo as previsões resultantes."
      ],
      "metadata": {
        "id": "J-KBvqgYlLwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================================================\n",
        "# =========================================================================================\n",
        "# =========================================================================================\n",
        "# =========================================================================================\n",
        "# =========================================================================================\n",
        "# =========================================================================================\n",
        "# =========================================================================================\n",
        "# =========================================================================================\n",
        "# =========================================================================================\n",
        "# ========================================================================================="
      ],
      "metadata": {
        "id": "Nr0zbmKJlue1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preço por Tudo"
      ],
      "metadata": {
        "id": "M_5PER93v5Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install category_encoders"
      ],
      "metadata": {
        "id": "3nAT2DYTl9QX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNjXhoIlv0y8"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from category_encoders import OneHotEncoder\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "\n",
        "from ipywidgets import Dropdown, FloatSlider, IntSlider, interact"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def limpeza(filepath):\n",
        "    # Read CSV file\n",
        "    df = pd.read_csv(filepath)\n",
        "\n",
        "    # Apartments in \"Capital Federal\", less than 400,000\n",
        "    mask_ba = df[\"place_with_parent_names\"].str.contains(\"Capital Federal\")\n",
        "    mask_apt = df[\"property_type\"] == \"apartment\"\n",
        "    mask_price = df[\"price_aprox_usd\"] < 400_000\n",
        "    df = df[mask_ba & mask_apt & mask_price]\n",
        "\n",
        "    # Remove outliers for \"surface_covered_in_m2\"\n",
        "    low, high = df[\"surface_covered_in_m2\"].quantile([0.1, 0.9])\n",
        "    mask_area = df[\"surface_covered_in_m2\"].between(low, high)\n",
        "    df = df[mask_area]\n",
        "\n",
        "    # Split \"lat-lon\" column\n",
        "    df[[\"lat\", \"lon\"]] = df[\"lat-lon\"].str.split(\",\", expand=True).astype(float)\n",
        "    df.drop(columns=\"lat-lon\", inplace=True)\n",
        "\n",
        "    # Get neighborhood name\n",
        "    df[\"neighborhood\"] = df[\"place_with_parent_names\"].str.split(\"|\", expand=True)[3]\n",
        "    df.drop(columns=\"place_with_parent_names\", inplace=True)\n",
        "\n",
        "    return df\n",
        ""
      ],
      "metadata": {
        "id": "Th_7BwEVmJyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos começar usando o que aprendemos para carregar todos os nossos arquivos CSV em um DataFrame."
      ],
      "metadata": {
        "id": "rsX5uezznBcZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício:\n",
        "Use o glob para criar uma lista que contenha os nomes dos arquivos para todos os arquivos CSV de imóveis em Buenos Aires no diretório de dados. Atribua esta lista à variável chamada `files`."
      ],
      "metadata": {
        "id": "unpPnHcFnDF8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U2XjXwa0nNe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na última vez, colocamos todos os nossos DataFrames em uma lista usando um loop `for`. Desta vez, vamos usar uma técnica de codificação mais compacta chamada compreensão de lista.\n",
        "\n",
        "A compreensão de lista é usada para iterar através de listas sem escrever loops explicitamente, o que é especialmente útil para filtrar dados de acordo com uma condição específica.\n",
        "\n",
        "__Exemplo:__\n",
        "```python\n",
        "price_mexican_pesos = [\n",
        "    35000000.0,\n",
        "    2000000.0,\n",
        "    2700000.0,\n",
        "    6347000.0,\n",
        "    6994543.16,\n",
        "    6617835.61,\n",
        "    670000.0,\n",
        "]\n",
        "\n",
        "# price_colombian_pesos = []\n",
        "# for price in price_mexican_pesos:\n",
        "#     price_colombian_pesos.append(price * 190)\n",
        "# print(price_colombian_pesos)\n",
        "\n",
        "price_colombian_pesos = [price * 190 for price in price_mexican_pesos]\n",
        "print(price_colombian_pesos)\n",
        "```"
      ],
      "metadata": {
        "id": "J_Q4kN2Fn6UN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício:\n",
        "Use sua função `limpeza` em uma compreensão de lista para criar uma lista chamada `frames`. A lista deve conter os DataFrames limpos para os nomes dos arquivos que você coletou em `files`."
      ],
      "metadata": {
        "id": "4dUYciE-n6_a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u00nBGwkoHch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício:\n",
        "Use `pd.concat` para concatenar os itens em `frames` em um único DataFrame chamado `df`. Certifique-se de definir o argumento `ignore_index` como `True`."
      ],
      "metadata": {
        "id": "1904cEkOpdbh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5612GX1bpgZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explorar\n",
        "\n",
        "A primeira coisa que precisamos considerar ao tentar usar todas as características do `df` são os valores ausentes.\n",
        "\n",
        "Embora seja verdade que você pode imputar valores ausentes, ainda é necessário ter dados suficientes em uma coluna para fazer uma boa imputação.\n",
        "\n",
        "Uma regra geral é que, se mais da metade dos dados em uma coluna estiver ausente, é melhor removê-la do que tentar imputar.\n",
        "\n",
        "Dê uma olhada na saída do `df.info()`. Existem colunas onde mais da metade dos valores são NaN? Se sim, essas colunas precisam ser removidas!"
      ],
      "metadata": {
        "id": "x3XQY8HipqA8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-R_SaasVp3Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício:\n",
        "Modifique sua função `limpeza` para remover quaisquer colunas que tenham mais da metade dos valores como NaN.\n",
        "\n",
        "Certifique-se de reexecutar todas as células acima antes de continuar."
      ],
      "metadata": {
        "id": "m0mwzvEep7xN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ebaf9SClqJwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A próxima coisa que precisamos observar são as colunas categóricas com baixa ou alta cardinalidade.\n",
        "\n",
        "Se houver apenas uma categoria em uma coluna, ela não fornecerá informações únicas para o nosso modelo. Por outro lado, colunas onde quase cada linha tem sua própria categoria não ajudarão o nosso modelo a identificar tendências úteis nos dados.\n",
        "\n",
        "Vamos dar uma olhada na cardinalidade de nossas características."
      ],
      "metadata": {
        "id": "xoK63jFcqRPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício:\n",
        "Calcule o número de valores únicos para cada característica não numérica em `df`."
      ],
      "metadata": {
        "id": "b6cYbxc6qkKE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dE-9vKRWqnOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui, podemos ver que colunas como \"operation\" têm apenas um valor, enquanto cada linha em \"properati_url\" tem um valor único. Esses são exemplos claros de características de baixa e alta cardinalidade que não devemos incluir em nosso modelo."
      ],
      "metadata": {
        "id": "S36HuTWPrVrt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício:\n",
        "Modifique sua função `limpeza` para remover características categóricas de alta e baixa cardinalidade."
      ],
      "metadata": {
        "id": "Qd_adsH8roNn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kB2dfN2drrLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Também é importante remover quaisquer colunas que constituam __vazamento__, ou seja, características que foram criadas usando nosso alvo ou que forneceriam ao nosso modelo informações que ele não teria acesso quando estiver em produção.\n",
        "\n",
        "__Em Outras Palavras:__\n",
        "\n",
        "__Vazamento__ é o uso de dados no treinamento do seu modelo que normalmente __não estariam disponíveis ao fazer previsões.__\n",
        "\n",
        "Por exemplo, suponha que queremos prever preços de imóveis em USD, mas incluímos preços de imóveis em Pesos Mexicanos em nosso modelo.\n",
        "\n",
        "Se assumirmos uma taxa de câmbio fixa ou quase constante, nosso modelo terá um erro baixo nos dados de treinamento, mas isso não refletirá seu desempenho em dados do mundo real."
      ],
      "metadata": {
        "id": "vDqu8K6kr7io"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício:\n",
        "Modifique sua função `limpeza` para remover quaisquer características que constituam vazamento."
      ],
      "metadata": {
        "id": "qeyft14muGpb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dKWC3oFluMgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, o último problema que precisamos observar é a multicolinearidade, ou seja, características em nossa matriz de características que estão altamente correlacionadas entre si. Uma boa maneira de detectar isso é usar um mapa de calor. Vamos criar um!"
      ],
      "metadata": {
        "id": "OgFt1z7Uua1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício:\n",
        "Plote um mapa de calor de correlação das características numéricas restantes em `df`.\n",
        "\n",
        "Como \"price_aprox_usd\" será seu alvo, você não precisa incluí-lo no mapa de calor."
      ],
      "metadata": {
        "id": "pb0dt2RKudvu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sjkiVqhRuoxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício:\n",
        "Modifique sua função `limpeza` para remover colunas que não tenham características fortemente correlacionadas na sua matriz de características."
      ],
      "metadata": {
        "id": "3BWhIRcZwkpS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SvyboxZ2woUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dividir Dados\n"
      ],
      "metadata": {
        "id": "YexSudgTw9Tx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício:\n",
        "Crie sua matriz de características `X_train` e vetor alvo `y_train`. Seu alvo é \"price_aprox_usd\". Suas características devem ser todas as colunas que permanecem no DataFrame que você limpou acima."
      ],
      "metadata": {
        "id": "Vq7JBfScxF_X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U43g2lARxG0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "id": "haya0KNxyyGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício:\n",
        "Calcule o erro absoluto médio de base para o seu modelo."
      ],
      "metadata": {
        "id": "x0gv8Zt_yziI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4h_Z2pCEy_OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iterar"
      ],
      "metadata": {
        "id": "xIEEN-j7zEh9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício:\n",
        "Crie um pipeline chamado model que contenha um OneHotEncoder, um SimpleImputer e um preditor Ridge."
      ],
      "metadata": {
        "id": "uhl6LSFezFuG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lgDo-UiDzLT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avaliar\n"
      ],
      "metadata": {
        "id": "o7T7kt2izVG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício:\n",
        "Calcule o erro absoluto médio de treinamento para suas previsões em comparação com os alvos verdadeiros em `y_train`."
      ],
      "metadata": {
        "id": "82tTieBhzbkL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aZDWVnmdzcPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício:\n",
        "Importe seus dados de teste `buenos-aires-features.csv` para um DataFrame e gere uma lista de previsões usando seu modelo."
      ],
      "metadata": {
        "id": "WzhW2Zu0zt4I"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p3laxbaJzxEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comunicar Resultados\n",
        "\n",
        "Nesta lição, confiamos em equações e visualizações para comunicar sobre nosso modelo.\n",
        "\n",
        "No entanto, em muitos projetos de ciência de dados, a comunicação significa fornecer aos stakeholders ferramentas que eles podem usar para implantar um modelo — em outras palavras, utilizá-lo em ação.\n",
        "\n",
        "Vamos analisar duas maneiras pelas quais você pode implantar este modelo.\n",
        "\n",
        "Uma das coisas que você pode ser solicitado a fazer é envolver seu modelo em uma função para que um programador possa fornecer entradas e, em seguida, receber uma previsão como saída."
      ],
      "metadata": {
        "id": "2j81rrd409Fm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício:\n",
        "Crie uma função chamada make_prediction que receba quatro argumentos (area, lat, lon e neighborhood) e retorne a previsão do seu modelo para o preço de um apartamento."
      ],
      "metadata": {
        "id": "-DsyWblF1LeT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a3eKlRem1USH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testar\n"
      ],
      "metadata": {
        "id": "yelOJPeo14U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outro tipo de implantação é criar um painel interativo, onde um usuário pode fornecer valores e receber uma previsão."
      ],
      "metadata": {
        "id": "2WVJoSqH1ppe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício:\n",
        "Adicione sua função `make_prediction` ao widget interativo abaixo, execute a célula e, em seguida, ajuste o widget para ver como o preço previsto do apartamento muda.\n",
        "\n",
        "- Crie uma função interativa nos Jupyter Widgets."
      ],
      "metadata": {
        "id": "uEMglX3y1uct"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QWPPwfhh11yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ótimo trabalho! Você deve ter percebido que há muitas maneiras de melhorar este painel.\n",
        "\n",
        "Por exemplo, um usuário pode selecionar um bairro e, em seguida, fornecer coordenadas de latitude e longitude que não estão naquele bairro. Também seria útil incluir uma visualização, como um mapa.\n",
        "\n",
        "De qualquer forma, este é um excelente primeiro passo para criar painéis dinâmicos que transformam seu modelo de uma abstração complicada em uma ferramenta concreta que qualquer pessoa pode acessar. Uma das partes mais importantes dos projetos de ciência de dados é criar produtos que as pessoas possam usar para facilitar seu trabalho ou suas vidas."
      ],
      "metadata": {
        "id": "2KBXhlrC18zW"
      }
    }
  ]
}